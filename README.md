# ðŸš€ `Cryptocurrency Data Pipeline (JSON-Based ETL)`

A complete **end-to-end data pipeline project** that extracts real-time cryptocurrency market data, transforms it into a clean analytical format, and serves it through an interactive **Streamlit dashboard**.

This project is designed as a **portfolio-ready Data Engineering project**, demonstrating modern ETL practices using **JSON data**, Python scripting, Jupyter notebooks, GitHub Actions automation, and lightweight analytics visualization.

## ðŸ“Œ `Project Overview`

This repository implements a **three-stage ETL pipeline**:

- **Extract** â€” Retrieve live cryptocurrency data from a public API  
- **Transform** â€” Clean, normalize, and standardize raw JSON data  
- **Load** â€” Produce a final analytics-ready dataset  

The final dataset is consumed by a **Streamlit dashboard** for interactive time-series analysis and monitoring.

## ðŸ§± `Project Structure`

```text
data-pipeline-project/
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ etl_pipeline.yml      Automated ETL workflow (GitHub Actions)
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.yaml         Centralized configuration
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ dashboard.py          Streamlit dashboard logic
â”‚   â””â”€â”€ app.py                Streamlit entry point
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  Raw JSON data (source of truth)
â”‚   â”œâ”€â”€ processed/            Cleaned & structured data
â”‚   â””â”€â”€ final/                Final analytics-ready dataset
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_extract_data.ipynb
â”‚   â”œâ”€â”€ 02_transform_data.ipynb
â”‚   â””â”€â”€ 03_load_data.ipynb
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ extract.py
â”‚   â”œâ”€â”€ transform.py
â”‚   â”œâ”€â”€ load.py
â”‚   â””â”€â”€ convert_to_json.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

---

### ðŸ”¹ BLOK 4 â€” ETL Pipeline Breakdown

```markdown
## ðŸ”„ `ETL Pipeline Breakdown`

### Extract â€” Raw Data
Cryptocurrency market data is retrieved from a public API and stored in **raw JSON format** without modification to preserve data integrity.  
Each extraction generates a **timestamped raw file** (e.g. `crypto_raw_YYYYMMDD_HHMMSS.json`) to ensure traceability and reproducibility.

### Transform â€” Processed Data
The transformation stage parses nested API responses, normalizes the schema, converts timestamps into readable datetime formats, handles missing or invalid values, and standardizes key fields such as price and volume.  
Processed outputs are saved as **timestamped JSON datasets**.

### Load â€” Final Dataset
The load stage performs lightweight validation and sorting before saving a **final analytics-ready dataset**, which serves as the single source of truth for downstream analysis and dashboard visualization.
